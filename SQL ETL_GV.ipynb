{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This is a test for doing some basic ETL on data.\n",
    "\n",
    "## The Goal\n",
    "The goal of this task is to take a pair excel files, load them into SQL, and then transform the dataset into a separate schema (called FHIR).\n",
    "\n",
    "### Input data\n",
    "The input data is an pair of excel files with patient information in it. Each file represents an extract of a data system, each made a month apart. Each file includes patients discharged during the last two months, so the data will have intersecting data points, but the union of the two is really what you want.  In the boilerplate code below, you can see the file paths and open them up in excel to browse it if you'd like. Feel free to ask questions about the file formatting.\n",
    "\n",
    "# Exercise\n",
    "\n",
    "## Load into SQL\n",
    "First, begin by loading the data into a SQL database. We have Postgres running for you already, so use that. \n",
    "Username: carta\n",
    "Password: password\n",
    "\n",
    "The data should be a union of the data in both extract files, with an update time corresponding to the newest update date available for each row.\n",
    "\n",
    "## Transform into FHIR\n",
    "\n",
    "After the data is loaded into SQL, you'll produce some FHIR resources from the data. In particular, there are two resources you'll make:\n",
    "\n",
    "1) Patient\n",
    "2) Encounter\n",
    "\n",
    "Both of those are defined on the FHIR website, here: http://fhir.org. We will do a validation on the data once it's done!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from carta_interview import Datasets, get_data_file\n",
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_extract1 = get_data_file(Datasets.PATIENT_EXTRACT1)\n",
    "patient_extract2 = get_data_file(Datasets.PATIENT_EXTRACT2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "('public', 'fhir')\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"postgres\",\n",
    "    user=\"carta\",\n",
    "    password=\"password\")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "table_sql = \"\"\"CREATE TABLE IF NOT EXISTS fhir (\n",
    "  encounter_id integer PRIMARY KEY ,\n",
    "  first_name varchar(45) NOT NULL,\n",
    "  last_name varchar(450) NOT NULL,\n",
    "  birth_date DATE NOT NULL,\n",
    "  admission_date DATE NOT NULL,\n",
    "  discharge_date DATE NOT NULL,\n",
    "  update_date DATE NOT NULL\n",
    ")\n",
    "\"\"\"\n",
    "cur.execute(table_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1234, 'John', 'Doe', '01/02/1999', '04/12/2002 5:00 PM', '04/13/2002 10:00 PM', '04/24/2002 6:00 AM']\n",
      "INSERT INTO fhir values\n",
      "INSERT INTO fhir values (1234, 'John', 'Doe', '01/02/1999', '04/12/2002 5:00 PM', '04/13/2002 10:00 PM', '04/24/2002 6:00 AM')\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "current transaction is aborted, commands ignored until end of transaction block\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-a1e7351dbe20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#print(record[\"Encounter ID\"], record[\"First Name\"], record[\"Last Name\"], record[\"Birth Date\"], record[\"Admission D/T\"], record[\"Discharge D/T\"], record[\"Update D/T\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: current transaction is aborted, commands ignored until end of transaction block\n"
     ]
    }
   ],
   "source": [
    "excel_1 = pd.read_excel(patient_extract1)\n",
    "excel_2 = pd.read_excel(patient_extract2)\n",
    "\n",
    "all_records = pd.concat([excel_1, excel_2])\n",
    "\n",
    "sql = \"\"\"INSERT INTO fhir values\"\"\"\n",
    "\n",
    "new_dataset = {}\n",
    "for index, record in all_records.head().iterrows():\n",
    "    if record[\"Encounter ID\"] in new_dataset:\n",
    "        if record[\"Update D/T\"] > new_dataset[record[\"Encounter ID\"]][6]:\n",
    "            new_dataset[record[\"Encounter ID\"]][6] = record[\"Update D/T\"]\n",
    "    else:\n",
    "        new_dataset[record[\"Encounter ID\"]] = [record[\"Encounter ID\"], record[\"First Name\"], record[\"Last Name\"], record[\"Birth Date\"], record[\"Admission D/T\"], record[\"Discharge D/T\"], record[\"Update D/T\"]]\n",
    "\n",
    "        # TODO Fix below code to update rocord in DB\n",
    "for record in new_dataset.values():\n",
    "    print(record)\n",
    "    print(sql)\n",
    "    sql = sql + \" (\" + str(record[0]) + \", '\" + record[1] + \"', '\" + record[2] + \"', '\" + record[3] + \"', '\" + record[4] + \"', '\" + record[5] + \"', '\" + record[6] + \"')\"\n",
    "    #print(record[\"Encounter ID\"], record[\"First Name\"], record[\"Last Name\"], record[\"Birth Date\"], record[\"Admission D/T\"], record[\"Discharge D/T\"], record[\"Update D/T\"])\n",
    "    print(sql)\n",
    "    cur.execute(sql)\n",
    "conn.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
